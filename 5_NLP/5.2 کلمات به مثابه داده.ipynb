{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMeQryuJ6CHy"
   },
   "source": [
    "<div dir=\"rtl\"><h1> کلمات به مثابه داده</h1>\n",
    "</div>\n",
    "<br />\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=XCjS3NZbPd8&list=PLY_JJbHwd6kftjlcbtChIKZfEPEfFRGcY&index=13&ab_channel=TheInternationalJournalists%27Network\">\n",
    "<img src=\"https://dotnet-talk.com/images/icfj/5_2.jpg\" width=\"50%\" alt=\"کلمات به مثابه داده - ویدیو\" />\n",
    "</a>\n",
    "\n",
    "<br />\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "در درس پیشین، مفاهیم اصلی را  NLP مرور کردیم. حال به چند مورد استفاده پیشرفته‌تر اشاره می‌کنیم.\n",
    "    </div>\n",
    "    <div dir=\"rtl\">\n",
    "ماشین نمی تواند کلمات را بفهمد مگر اینکه کلمات به داده هایی تبدیل شوند که برای ماشین قابل پردازش باشد. راه‌های زیادی برای انجام این کار وجود دارد؛ مثلا ذخیره کلمات به‌صورت کاراکترهای تایپ‌شده، اما برای انجام برخی کارها، روش‌های دیگری برای نمایش کلمات وجود دارد. در این درس ما به طور خاص به ذخیره کلمات به عنوان \"بردار\" (vectors) خواهیم پرداخت که به ما این امکان را می‌دهد تا میزان شباهت معنای دو کلمه با یکدیگر را بررسی کنیم. کلمه دیگر برای این بردار، جاساز (Embedding) است زیرا آنها معنای یک کلمه را می گیرند و سپس اعداد را به جای آن‌ها «جاسازی» می‌کنند.\n",
    "</div>\n",
    "<div dir=\"rtl\">\n",
    "در ادامه همچنین کتابخانه‌ای را بررسی می‌کنیم که از NLP برای تعیین احساس یک جمله، به ویژه مثبت یا منفی بودن آن استفاده می‌کند. جملات با احساسات منفی می تواند شامل انتقادها به یک محصول و یا حمله‌های پیامی به یک نامزد سیاسی باشد.\n",
    "</div>\n",
    "<div dir=\"rtl\">\n",
    "در پایان نیز مفهوم تولید متن را بررسی خواهیم کرد. این مفهوم به معنای توان کامپیوتر برای نوشتن جملات، پاراگراف و حتی یک متن کامل است. این همان کاری است که ChatGPT انجام می‌دهد. ما حتی یک مدل  GPT-2 آموزش‌دیده به زبان فارسی را مستقیماً روی لپ‌تاپ شما به اجرا در خواهیم آورد تا از نحوه کار آن سر در بیاوریم. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\"><h3>کتابخانه hazm</h3></div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "ابتدا کتابخانه Hazm را که در نوت‌بوک پیشین از آن استفاده کردیم، وارد می کنیم. در اینجا هم از همان روش توکنیزه کردن کلمات استفاده خواهیم کرد.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n13gAj3g9jO0"
   },
   "outputs": [],
   "source": [
    "import hazm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3O0doK84FNw"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<h3>\n",
    "کتابخانه Gensim\n",
    "</h3>\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "از این کتابخانه هم برای مقایسه کلمات و بررسی میزان تشابه آن‌ها استفاده خواهیم کرد.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pMtIp6E4Dxc"
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h3>\n",
    "کتابخانه Numpy\n",
    "</h3>\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "در مورد این کتابخانه کارآمد هم در دروس پیشین صحبت کرده‌ایم. از آن برای ذخیره و پردازش برخی داده‌های استفاده خواهیم کرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h3>\n",
    "کتابخانه Scikit-learn\n",
    "</h3>\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "این بسته (پکیج) شامل مجموعه‌ای از روش‌های سنتی یادگیری ماشینی نظیر کشیدن خط میان داده‌ها (وصل کردن داده‌ها به یکدیگر از طریق یک خط) است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h3>\n",
    "کتابخانه های torch and transformers\n",
    "</h3>\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "این دو کتابخانه را بعدتر می‌ریزیم. از آن‌ها برای استفاده از فن‌آوری‌های پیشرفته NLP استفاده می‌شود. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvRo3eOj6LMQ"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<h2>\n",
    "کلمات به مثابه بردار\n",
    "</h2>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "    کامپیوترها مفاهیم یا کلمات را درک نمی‌کنند، بلکه عملیات ریاضی را می‌فهمند. بنابراین برای انجام کارهای پیشرفته NLP باید بتوانیم مسئله خود را به یک موضوع ریاضی تبدیل کنیم. یک ایده کلیدی \n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "این است که کلمات را نه به عنوان متن، بلکه بیشتر به عنوان اعداد نشان دهیم. این کار به ما امکان می دهد تا انواع عملیات ریاضی را روی این اعداد انجام دهیم.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "یک روش، نمایش کلمات به عنوان بردار (vectors) است. در این جا، بردار به معنای مجموعه‌ای از اعداد است. به عنوان مثال (1, 2, 3, 4) یک بردار چهار بعدی است؛ یعنی شامل چهار رقم است.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "ما می‌توانیم کلمات را با داشتن یک بردار چندبعدی به نمایش در بیاوریم. مثلا کلمه \"the\" ممکن است (1، 0، 0، 0، ...) و \"و\" ممکن است (0، 1، 0، 0، 0، ...) باشد و غیره. مدل هایی مانند GPT کلمات را اینگونه می بینند.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "راه دیگر این است که از چند بعد استفاده کنید و هر کلمه را در نزدیک‌ترین فاصله از کلمه مشابهش قرار دهید. به عنوان مثال، می‌توانید \"شکلات\" را به عنوان (0.9، 1.0) و \"شکر\" را می توان به عنوان (1.0، 0.9) نشان داد، در حالی که \"ترش\" را می توان با (-1.0، -1.0) نشان داد. ما می‌توانیم از یک عدد استفاده کنیم، بنابراین \"the\" ممکن است 0.001 و \"and\" ممکن است 0.002 باشد، اما اگر از اعداد متعدد استفاده کنیم، می‌توانیم ارتباطات پیچیده‌تری بین کلمات را نشان دهیم.\n",
    "    \n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "یک روش دیگر استفاده از چند بُعدی است و هر کلمه را به نزدیک‌ترین کلماتی که شباهتی به آن دارند قرار می‌دهد. به عنوان مثال، \"شکلات\" می‌تواند به شکل (0.9، 1.0) نمایش داده شود و \"شکر\" می‌تواند به شکل (1.0، 0.9) نمایش داده شود، در حالی که \"ترش\" می‌تواند با (-1.0، -1.0) نمایش داده شود. می‌توانیم از یک عدد تک‌بُعدی استفاده کنیم، بنابراین \"the\" ممکن است 0.001 و \"and\" ممکن است 0.002 باشد، اما اگر از چند عدد استفاده کنیم، می‌توانیم ارتباطات پیچیده‌تری بین کلمات نمایش دهیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du0rWAs3_Wco"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "   انتخاب دستی این اعداد به دلیل تعداد زیاد کلمات ممکن تقریباً غیرممکن است، بنابراین این مدل‌ها باید \"آموزش داده\" شوند و بهترین نمایشی از هر کلمه را بیابند و یاد بگیرند که کدام کلمات به یکدیگر شبیه هستند. این بدان معنی است که آنها باید از مثال‌های ارائه شده به آنها یاد بگیرند.\n",
    "</div>\n",
    "<div dir=\"rtl\">\n",
    "   معمولاً این مدل‌ها با مجموعه‌های بسیار بزرگی از داده‌ها آموزش می‌بینند، اما در حال حاضر ما فقط از چند جمله استفاده خواهیم کرد، زیرا زمان زیادی برای آموزش روی مجموعه‌های بزرگ نیاز است.یکی از روش‌های محبوب برای یافتن این بردارها، مدلی به نام Word2Vec است که به ما امکان می‌دهد از داده خود برای آموزش یک مدل استفاده کنیم که یک کلمه مانند \"شکر\" را به یک بردار مانند (0.9، 1.0) تبدیل کند. حالا این الگوریتم را وارد خواهیم کرد:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B00JiDVi6IgV"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31j6bkLp68Ea"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "برای آموزش یک مدل Word2Vec، ابتدا باید ورودی را به یک سری کلمه تبدیل کنیم. در درس قبلی می‌دانیم که چگونه این کار را انجام دهیم. ما متن را بارگیری کرده و سپس از <span style=\"color: orange\">hazm</span> برای تبدیل آن به یک لیست از کلمات استفاده خواهیم کرد.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "برای مثال ما 10 جمله در مورد قایق‌ها و آب خواهیم داشت، اما هر کس می‌تواند این کار را با هر متنی که می‌خواهد انجام دهد، مانند چندین سند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "در کد زیر ابتدا متن را به جملات تبدیل می کنیم و سپس در خط بعدی کلمات هر جمله را به دست می آوریم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-z9q8cVY9aJe",
    "outputId": "6a326ca7-59e5-4e65-c7c0-b6f113eb0ff8"
   },
   "outputs": [],
   "source": [
    "sentence_tokenizer = hazm.SentenceTokenizer()\n",
    "example_text = \"\"\"من دوست دارم با قایق بر روی آب بگردم.\n",
    "این قایق بادبانی بسیار زیبا و رنگین است.\n",
    "آب دریا بسیار شور است.\n",
    "ما باید قبل از قایق سواری، جلیقه نجات بپوشیم.\n",
    "این قایق موتوری بسیار سرعت زیادی دارد.\n",
    "آب رودخانه بسیار شفاف و تمیز است.\n",
    "ما با قایق های کاغذی بازی می کنیم.\n",
    "این قایق تفریحی بسیار بزرگ و لوکس است.\n",
    "آب باران بسیار خنک و تازه است.\n",
    "ما با قایق های چوبی ماهی می گیریم.\"\"\"\n",
    "# we will first convert to sentences\n",
    "raw_sentences = sentence_tokenizer.tokenize(example_text)\n",
    "# and now get all words for each sentence\n",
    "examples = [hazm.word_tokenize(sentence) for sentence in raw_sentences]\n",
    "print(examples[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NsfJOP59x8V"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "اکنون که داده‌هایمان بارگیری و پردازش شده‌اند، می‌توانیم یک مدل ساده Word2Vec آموزش دهیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jO_gm1oW6lrl",
    "outputId": "3e69dcf5-3a91-4f90-feef-c07d5af54bae"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(examples, min_count=1, vector_size=10, workers=3, window=3, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PkIrDJe7Xvd"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "تبریک می‌گویم! شما موفق شدید اولین مدل یادگیری ماشین خود را آموزش دهید!\n",
    "</div>\n",
    "<br />\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "در بالا، می‌بینیم که مدل Word2Vec را با داده‌های <span style=\"color: orange\">examples</span> خود ایجاد می‌کنیم. <span style=\"color: orange\">min_count</span> به ما اجازه می‌دهد کلمات نادری را که کمتر از آن تعداد تکرار دارند (اینجا هیچ کلمه‌ای را حذف نمی‌کنیم)، حذف کنیم. <span style=\"color: orange\">vector_size</span> تعداد ابعاد بردارهای کلمات را تعیین می‌کند. <span style=\"color: orange\">window</span> اجازه می‌دهد که کلمات چقدر نزدیک یکدیگر باشند تا به عنوان مرتبط در نظر گرفته شوند. در نهایت، <span style=\"color: orange\">sg</span> الگوریتم آموزشی را که می‌خواهیم استفاده کنیم مشخص می‌کند، که در اینجا skip gram را انتخاب کرده‌ایم. برای دریافت اطلاعات بیشتر درباره این پارامترها، می‌توانید <a href=\"https://radimrehurek.com/gensim/models/word2vec.html\">در مستندات رسمی</a> مراجعه کنید.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "ما می‌توانیم حالا اعدادی را که هر کلمه را نمایان می‌کنند را مشاهده کنیم. فقط کافیست مراحل زیر را انجام دهیم تا ببینیم چگونه کلمه boat نمایان می‌شود:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['قایق']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "زیرا این اعداد هستند، می‌توانیم ببینیم که چقدر اعداد یک کلمه به اعداد دیگر نزدیک هستند. به طور مشابه، همانطور که ۰.۹ و ۰.۸ نزدیک‌تر از -۰.۷ هستند، می‌توانیم در مواقعی که هر کلمه دارای بسیاری از اعداد است (نه فقط یک عدد)، این موضوع را نیز انجام دهیم. کتابخانه Word2Vec به ما یک راه آسان برای انجام این کار می‌دهد.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "برای نمایش این موضوع، ما خواهیم محاسبه کنیم چقدر کلمات \"دریا\" و \"شور\" نسبت به \"رودخانه\" و \"شور\" شباهت دارند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "GDbLv_mY-X7_",
    "outputId": "1003d6e5-b033-4c69-fed0-bab73263a247",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.wv.similarity('دریا', 'شور')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\">\n",
    "همانطور که مشاهده می‌کنید، اینها یک امتیاز مثبت نشان می‌دهند که به معنای وجود شباهتی است. حالا بیایید نتیجه را برای \"رودخانه\" و \"شور\" ببینیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('رودخانه', 'شور')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "این امتیاز منفی است که نشان می‌دهد کلمات \"رودخانه\" و \"شور\" به یکدیگر وابسته نیستند.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "این استفاده‌ها نسبتاً ساده هستند، اما این فناوری دارای قابلیت‌های مهمی است. به عنوان مثال، ممکن است بخواهیم محل توضیح روش‌های عملیاتی را در یک سند طولانی پیدا کنیم، اما این سند ممکن است از عبارتی متفاوت مانند \"روش شناخته شده\" استفاده کند. با استفاده از این بردارها، ما می‌توانیم این متن را پیدا کنیم، حتی اگر با کلمات جستجوی ما مطابقت نداشته باشد.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "ابزارهایی مانند مدل‌های GPT شرکت OpenAI می‌توانند این بردارها را نه فقط برای کلمات تکی، بلکه برای سند‌های کامل نیز تولید کنند، بنابراین اکنون می‌توانید جستجوی پیچیده‌ای مانند \"قوانین مربوط به فروش قایق‌ها\" را انجام دهید و اگر تمام اسناد بردارهای مربوط به خود را ایجاد کرده باشند، آن اسنادی که جزئیات این موارد را دارند، بیشترین شباهت را خواهند داشت.\n",
    "\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "<h4>محدودیت‌ها</h4>\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "با تمام مدل‌های پردازش زبان طبیعی، اگر یک کلمه را قبلاً در داده‌های آموزش خود نبیند، قادر به پردازش آن نخواهد بود. بنابراین، اگر می‌خواهید از یک کلمه خاص استفاده کنید، مطمئن شوید که آن در داده‌های آموزش حضور داشته باشد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=\"rtl\">\n",
    "تحلیل احساسات\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "تحلیل احساسات به وظیفه شناسایی و استخراج قطبیت های احساسی (مثبت یا منفی) یک متن داده شده می‌پردازد. تحلیل احساسات می‌تواند برای کاربردهای مختلفی مفید باشد، مانند تحلیل رسانه‌های اجتماعی، بازخورد مشتریان، نقد و بررسی محصولات و غیره.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "برای انجام تحلیل احساسات، مدل‌های پیشرفته موجود است، اما ما از ابزار Word2Vec که در بالا استفاده کرده‌ایم، برای ایجاد روشی ساده از ابتدا که قادر به شناسایی احساسات مثبت یا منفی است، استفاده خواهیم کرد.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "ابتدا برخی از مثال‌های سفارشی را اضافه می‌کنیم. برای استفاده واقعی، ما نیاز به داده‌های آموزشی بیشتری داریم، اما برای این درس، فقط از چند جمله هر نوع استفاده خواهیم کرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_text = \"من امروز خیلی خوشحالم چون کارم را تمام کردم. او به من گل زیبایی هدیه داد و من را شاد کرد. ما با دوستانمان به پارک رفتیم و خیلی لذت بردیم. این فیلم بسیار جالب و خنده دار بود. من از موفقیت شما خوشحالم. او با لبخند گفت: من عاشق تو هستم. مادرم برای من غذای مورد علاقه ام درست کرد. این کتاب بسیار جذاب و آموزنده بود. ما در قرعه کشی یک سفر رایگان برنده شدیم. این آهنگ بسیار شاد و شنیدنی است.\"\n",
    "negative_text = \"من امروز خیلی ناراحتم چون کارم را از دست دادم. او به من گفت که من بی استعداد و بی ارزش هستم. ما با دوستانمان به سینما رفتیم ولی فیلم بسیار بد و خسته کننده بود. این کتاب بسیار خشک و بی معنی بود. من از شکست شما لذت می برم. او با تنفر گفت: من از تو متنفرم. مادرم به من گفت که من هیچ وقت نمی توانم به آرزوهایم برسم. این آهنگ بسیار زشت و ناهنجار است. ما در قرعه کشی یک جایزه بزرگ از دست دادیم. این غذا بسیار تلخ و ترش است.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "حالا ما این جملات را برای آموزش آماده خواهیم کرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokenizer = hazm.SentenceTokenizer()\n",
    "positive_sentences = sentence_tokenizer.tokenize(positive_text)\n",
    "negative_sentences = sentence_tokenizer.tokenize(negative_text)\n",
    "# now add the positive and negative sentences together so we can train a model on all of them\n",
    "raw_sentences = positive_sentences + negative_sentences\n",
    "examples = [hazm.word_tokenize(sentence) for sentence in raw_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "و حال می‌توانیم مدل <span style=\"color: orange\">Word2Vec</span> را آموزش دهیم. از یک مقدار <span style=\"color: orange\">vector_size</span> برابر با 5 استفاده می‌کنیم زیرا داده‌های آموزشی زیادی نداریم. اگر از یک عدد بزرگتر استفاده کنیم، مدل آموزش داده شده سخت‌تر خواهد شد زیرا برای هر کلمه تعداد زیادی عدد خواهیم داشت اما فقط چند نمونه برای آموزش آن داریم. برای مجموعه داده‌های آموزش بزرگتر، استفاده از بعد بیشتر به مدل کمک می‌کند تا شرایط پیچیده‌تری را درک کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(examples, min_count=1, vector_size=5, workers=3, window=3, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\">\n",
    "حالا یک تابع ایجاد می‌کنیم که بتواند بردارهای کلمات را به عنوان ورودی دریافت کند و یک بردار تک برای یک جمله کامل ایجاد کند. به این ترتیب، می‌توانیم یک جمله را به عنوان یک مجموعه اعداد تنها نمایش دهیم به جای چند کلمه.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_vector(text):\n",
    "  # tokenize the text\n",
    "  tokens = hazm.word_tokenize(text)\n",
    "  # filter out punctuation and non-alphabetic tokens\n",
    "  tokens = [token for token in tokens if token.isalpha()]\n",
    "  # get the vectors of the tokens\n",
    "  vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "  # return the average vector or a zero vector if empty\n",
    "  return np.mean(vectors, axis=0) if vectors else np.zeros(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\">\n",
    "حالا یک مدل ساده و رایج به نام <span style=\"color: orange\">رگرسیون لجستیک</span> را راه اندازی و آموزش می‌دهیم. این مدل یک روش ساده و شایع برای یادگیری بهترین روش جداسازی دو گروه است، در اینجا جملات مثبت و منفی. این مدل از آمار مشتق شده است و یک روش قدیمی و قابل اعتماد است.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "برای مدل، یک آرایه به نام <span style=\"color: orange\">train_vectors</span> راه اندازی می‌کنیم که شامل تمام جملاتی است که برای آموزش استفاده می‌کنیم، و سپس <span style=\"color: orange\">y_train</span> را تعیین می‌کنیم که احساس مثبت را با ۱ و احساس منفی را با ۰ نشان می‌دهد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.concatenate((\n",
    "    np.array([get_average_vector(sentence) for sentence in positive_sentences]),\n",
    "    np.array([get_average_vector(sentence) for sentence in negative_sentences])))\n",
    "y_train = np.concatenate((np.ones(len(positive_sentences)), np.zeros(len(negative_sentences))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\">\n",
    "حالا مدل ساده را آموزش خواهیم داد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "حالا یک تابع تعریف خواهیم کرد که از مدلی که به تازگی آموزش دادیم استفاده کند و در صورتی که فکر کند متن مثبت است، \"Positive\" را چاپ کند و در صورتی که فکر کند متن منفی است، \"Negative\" را چاپ کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # this converts the text to a vector and then shows it to the model\n",
    "    y_pred = clf.predict([get_average_vector(text)])\n",
    "    if y_pred < 0.5:\n",
    "        print(\"Positive!\")\n",
    "    else:\n",
    "        print(\"Negative!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "حالا چند نمونه از عملکرد مدل را در پیش بینی متن مثبت مشاهده خواهیم کرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example positive sentence\n",
    "predict(\"من از موفقیت شما خوشحالم\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example positive sentence\n",
    "predict(\"من با لبخند گفتم: من از شما خیلی خوشحالم..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "حالا چند نمونه از متن منفی را بررسی می‌کنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example negative sentence\n",
    "predict(\"او به من گفت که من بی استعداد و بی ارزش هستم\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example negative sentence\n",
    "predict(\"مادرم به من گفت که من بی معنی و بی ارزش هستم.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does not work perfectly though and may make mistakes. For example, the below negative sentence is misclassified as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example negative sentence which is incorrectly classified\n",
    "predict(\"من از کارم خسته شدم و هیچ لذتی نبردم.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\">\n",
    "برای رفع این مشکل، نیاز به داده‌های آموزش بیشتر و یک مدل پیچیده‌تر از رگرسیون لجستیک داریم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 dir=\"rtl\">\n",
    "نتیجه‌گیری تحلیل احساسات\n",
    "</h4>\n",
    "\n",
    "\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "اینکه ما قابلیت تولید بردارهای کلمات را برداشت کرده‌ایم و از آن برای ساخت و آموزش یک مدل ساده برای تحلیل احساسات استفاده کرده‌ایم. یکی از درس‌های کلیدی در اینجا این است که چقدر توانایی نمایش کلمات به صورت اعداد قدرتمند است و این امکان را به ما می‌دهد تا از ابزارها و مدل‌های آماری مختلف مانند رگرسیون لجستیک برای توسعه مدل‌ها استفاده کنیم.\n",
    "</div><br /><div dir=\"rtl\">\n",
    "در حوزه پردازش زبان طبیعی، علاوه بر تحلیل احساسات، وظایف \"طبقه‌بندی\" دیگری نیز وجود دارد. به عنوان مثال، ممکن است بخواهیم عبارات رسمی و غیررسمی را دسته‌بندی کنیم.\n",
    "</div><br /><div dir=\"rtl\">\n",
    "به هر حال، برای هر وظیفه طبقه‌بندی خاص، فرایند اصلی همانند آنچه که در اینجا یاد گرفتیم، استفاده خواهد شد:\n",
    "</div>\n",
    "\n",
    "<ol dir=\"rtl\">\n",
    "<li>\n",
    "توکن‌بندی متن به کلمات فردی یا گروهی از حروف\n",
    "</li>\n",
    "<li>\n",
    "تبدیل این کلمات به نمایشی عددی که می‌توان با آموزش یک مدل Word2Vec انجام داد یا از مدل‌های آموزش داده شده توسط شرکت‌هایی مانند OpenAI استفاده کرد.\n",
    "</li>\n",
    "<li>\n",
    "آموزش یک مدل بر اساس این نمایش عددی. این می‌تواند به عنوان یک مدل آماری ساده یا به عنوان سیستم‌های پیشرفته‌تری مانند ChatGPT باشد.\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2  dir=\"rtl\">تولید متن</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "تولید متن، پیشرفته‌ترین فناوری پردازش زبان طبیعی است که در آن از مدل‌های اخیر مانند ChatGPT استفاده می‌شود. در واقع، در ادامه قصد داریم نسخه‌ای پیشتر از ChatGPT به نام GPT-2 را اجرا کنیم که بر روی متن‌های فارسی آموزش دیده است. این فرآیند به طور کامل در کامپیوتر شما اجرا می‌شود، بنابراین ممکن است زمانی برای تولید متن طولانی طولانی برای انجام عملیات لازم باشد، اما برای پروژه‌های بزرگ پردازش زبان طبیعی، می‌توان از سرورها یا لپتاپ‌های قدرتمندتری استفاده کرد تا به سرعت و کارآیی بیشتری دست پیدا کنیم.\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "ابتدا برخی از بسته‌ها را باید نصب کنیم. به دلیل اینکه نصب این بسته‌ها ممکن است زمان زیادی برای تکمیل نیاز داشته باشد، آن‌ها در نصب اولیه درج نشده‌اند.</div>\n",
    "\n",
    "<br />\n",
    "\n",
    "<h3 dir=\"rtl\">ترانسفورمرها</h3>\n",
    "\n",
    "<br />\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "این کتابخانه به ما امکان می‌دهد مدل‌هایی که قبلاً آموزش داده شده‌اند را دانلود و اجرا کنیم، مانند مدلی که امروز استفاده می‌کنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 dir=\"rtl\">کتابخانه Torch</h3>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "این یک کتابخانه کامل برای یادگیری ماشین است که می‌توان از آن برای ساخت و استفاده از مدل‌های پیشرفته‌ترین و جدیدترین استفاده کرد. این کتابخانه توسط شرکت‌هایی مانند فیسبوک، مایکروسافت، تویوتا، تسلا و اوبر و بسیاری دیگر استفاده می‌شود. در این روزها، ما از آن برای اجرای یک مدلی که قبلاً آموزش دیده شده استفاده خواهیم کرد، اما می‌توانید مدل‌های خودتان را ساخته و آموزش دهید.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import *\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\">\n",
    "حالا می‌خواهیم یک مدل پیش‌آموزش‌داده شده را دانلود و بارگیری کنیم زیرا برای آموزش یک مدل تولید متن روی لپتاپ‌های معمولی به مدت چند ماه نیاز خواهد بود. \"پیش‌آموزش‌داده شده\" کلمه‌ای است که در NLP استفاده می‌شود وقتی کسی دیگر مدل را طراحی و آموزش داده است و شما فقط آن را بارگیری و استفاده می‌کنید. وقتی مردم از ChatGPT استفاده می‌کنند، از یک مدل پیش‌آموزش‌داده شده استفاده می‌کنند.\n",
    "</div>\n",
    "<br />\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "حالا یک مدل پیش‌آموزش‌داده شده فارسی را بارگیری خواهیم کرد. این از یک سرویس به نام <a href=\"https://huggingface.co/\">Hugging Face</a> استفاده می‌کند که به افراد امکان می‌دهد مدل‌هایی که آموزش داده‌اند را بارگذاری و سپس آنها را برای دیگران قابل دانلود و استفاده کند. ما از مدل \"<a href=\"https://huggingface.co/HooshvareLab/gpt2-fa\">Hooshvarelab/gpt2-fa</a>\" استفاده خواهیم کرد، اما می‌توانید همه مدل‌هایی که برای زبان فارسی پشتیبانی دارند را در <a href=\"https://huggingface.co/models?language=fa\">سایت مدل‌های Hugging Face</a> مشاهده کنید. پیدا کردن یک مدل مناسب برای مورد استفاده خود همیشه آسان نیست، اما بیشتر مدل‌ها یا مدل‌های تولید متن هستند یا مدل‌هایی که می‌توانند گفتار را به متن تبدیل کنند.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "بارگیری ممکن است چند دقیقه طول بکشد زیرا نیاز است تا مدل را بر روی لپ‌تاپ خود دانلود کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/gpt2-fa\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"HooshvareLab/gpt2-fa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "این <span style=\"color: orange\">tokenizer</span> مشابه توکن‌سازهای کلمه‌ای است که تاکنون از <span style=\"color: orange\">hazm</span> استفاده کرده‌ایم، اما بردارهای بسیار بزرگی تولید می‌کند که مدل GPT-2 آموزش دیده می‌تواند آنها را درک کند.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "<span style=\"color: orange\">مدل</span> سپس مسئول تولید متن خواهد بود.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "حالا یک تابع ایجاد خواهیم کرد که به ما امکان تولید متن و تعیین مقدار متن مورد نظر را می‌دهد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=50, num_return_sequences=1, do_sample=True):\n",
    "  # encode the prompt\n",
    "  input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "  # generate output ids\n",
    "  output_ids = model.generate(input_ids,\n",
    "                              max_length=max_length,\n",
    "                              num_return_sequences=num_return_sequences,\n",
    "                              do_sample=do_sample)\n",
    "  # decode output ids\n",
    "  output_texts = tokenizer.batch_decode(output_ids)\n",
    "  # return output texts\n",
    "  return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\">\n",
    "حالا می‌توانیم از این تابع برای تولید متن با استفاده از یک پیشنهاد ساده استفاده کنیم. \"پیشنهاد\" نامی است که به اولین کلماتی می‌گوییم که به مدل نشان می‌دهیم و سپس مدل کلماتی را بعد از متن پیشنهاد اضافه خواهد کرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"داستانی درباره یک قهرمان نوشته شده است که\"\n",
    "output_texts = generate_text(prompt)\n",
    "for i, text in enumerate(output_texts):\n",
    "  print(f\"Text {i+1}:\")\n",
    "  print(text)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "این یکی از متون ممکن است که مدل از پیشنهاد تولید کرده است. این یک متن روان و هماهنگ است که یک داستان معمولی از مسیر یک قهرمان را معرفی می‌کند. می‌توانیم ببینیم که مدل برخی از عناصر مشترک داستان‌نویسی را یادگرفته است، مانند تعیین هدف، تضاد و چالش برای قهرمان.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "همچنین می‌توانیم با تغییر پارامتر <span style=\"color: orange\">num_return_sequences</span> بیش از یک متن را از همان پیش‌بینی تولید کنیم. به عنوان مثال:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"داستانی درباره یک قهرمان نوشته شده است که\"\n",
    "output_texts = generate_text(prompt, num_return_sequences=3)\n",
    "for i, text in enumerate(output_texts):\n",
    "  print(f\"Text {i+1}:\")\n",
    "  print(text)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "همانطور که می‌بینید، هر بار می‌تواند داستان‌های بسیار متفاوتی تولید کند. توصیه می‌کنم که با ویرایش جمله \"prompt\" خود، آن را امتحان کنید و ببینید که چه متنی تولید می‌شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=\"rtl\">\n",
    "ما همچنین می‌توانیم پارامتر max_length را تغییر دهیم تا متونی با طول‌های بیشتر یا کمتر تولید کنیم. به عنوان مثال:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"سوال: آیا قایق ها می توانند پرواز کنند؟ بله یا خیر. پاسخ:\"\n",
    "output_texts = generate_text(prompt, num_return_sequences=3, max_length=20)\n",
    "for i, text in enumerate(output_texts):\n",
    "  print(f\"Text {i+1}:\")\n",
    "  print(text)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "همانطور که می‌بینید، پاسخ‌ها ممکن است درست یا دقیق نباشند، اما با یک مدل پیشرفته‌تر، می‌توان از آن برای تکمیل اطلاعات استفاده کرد. یک نکته مهمی که همیشه باید به خاطر داشته باشید هنگام استفاده از این مدل‌ها این است که قبل از استفاده از خروجی آنها، باید با دقت آن را بررسی کرده و تصحیح و بررسی واقعیت‌های آن انجام دهید. در حال حاضر روشی برای تضمین اینکه این مدل‌ها محتوای مضر یا غلط تولید نکنند، وجود ندارد. هرگز نباید متن تولیدشده توسط هوش مصنوعی را بدون ویرایش و بررسی واقعیت‌ها منتشر کنید.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "به عنوان مثال، می‌توان هر جمله را در یک سند گرفت و به مدل هر جمله را با فرمت \"آیا جمله \"این شرکت برای بیمه خودرو مناسب است.\" به یک شرکت بیمه اشاره دارد؟\" ارائه داد و سپس اگر مدل در پاسخ خود \"بله\" را خروجی دهد، می‌توان این را دسته‌بندی کرد. این می‌تواند یک روش برای یافتن هر اشاره به شرکت‌های بیمه در یک سند مثلاً باشد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "این فناوری از تولید پیش‌نویس‌های داستان‌های خبری تا پاسخ به سوالات درباره متن و اسناد، امکانات بسیاری را داراست.\n",
    "</div>\n",
    "<br />\n",
    "<h2 dir=\"rtl\">چگونگی عملکرد آنها</h2>\n",
    "<br />\n",
    "<div dir=\"rtl\">\n",
    "مدلی که به تازگی استفاده کرده‌ایم از چیزی به نام یادگیری عمیق استفاده می‌کند. این روش به ما امکان می‌دهد که مجموعه‌های بزرگی از داده‌ها را جمع‌آوری کرده و سپس یک مدل را آموزش دهیم که شامل میلیون‌ها یا میلیاردها پارامتر است که می‌توانیم آنها را به عنوان دستگردهایی در نظر بگیریم که مدل می‌تواند آنها را بچرخاند تا نحوه رفتار خود را تغییر دهد. هیچ انسانی قوانینی برای تعیین اینکه مدل باید چگونه کلمه بعدی را تشخیص دهد، نمی‌نویسد. بلکه این مدل‌ها به طور خودکار از طریق ایجاد خطاها در تولید و سپس تنظیم پارامترهای خود، یاد می‌گیرند.\n",
    "</div>\n",
    "<br />\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "برای این مدل خاص، آن را روی متون فارسی بسیاری آموزش داده‌اند و آموزش داده شده است که پیش‌بینی کند کلمه بعدی چیست. این باعث می‌شود تا بتواند جملاتی را با دستور زبان و معنا درست بنویسد. برای مدل‌های کوچک، ممکن است خطاهایی داشته باشند و یا درست نباشند، اما با اضافه کردن پارامترهای بیشتر، مدل می‌تواند حتی جزئیات بیشتری از کارکرد زبان‌ها را یاد بگیرد و در نتیجه عملکرد بهتری داشته باشد.\n",
    "</div>\n",
    "<br />\n",
    "<h2 dir=\"rtl\">نتیجه گیری</h2>\n",
    "<br />\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "اکنون از موارد استفاده پیشرفته‌ی NLP خیلی چیزها یاد گرفتیم، از جمله اجرای یک نسخه قدیمی‌تر از مدل‌های یادگیری ماشین که در پشتیبانی از ChatGPT قرار دارند. همه‌ی NLP مدرن بر اساس تبدیل متن انسان به اعدادی به نام بردارها یا جاسازی‌ها استوار است و یاد گرفتیم چگونه می‌توانیم مدل خود را آموزش دهیم تا بتوانیم بردارهایی پیدا کنیم که از آنها برای مقایسه شباهت کلمات استفاده کنیم. سپس دیدیم چگونه می‌توانیم مدل سفارشی خود را بسازیم و آموزش دهیم تا تشخیص دهد که متن مثبت است یا منفی، و دیدیم که این وابسته به همان بردارهای کلمه است که در ابتدای درس یاد گرفته بودیم.\n",
    "</div>\n",
    "<br />\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "سرانجام، یاد گرفتیم چگونه از مدل‌های تولید متن استفاده کنیم و حتی چگونه بتوانیم یکی از آنها را مستقیماً روی کامپیوتر خود اجرا کنیم. این مدل‌ها بسیار پیچیده هستند، بنابراین یادگیری تمام جزئیات درباره نحوه کار آنها چالش‌برانگیز است، اما ما اصول اصلی را پوشش دادیم تا بتوانید شروع کنید به بررسی نحوه عملکرد و استفاده از این مدل‌ها.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
